{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This tutorial will walk you through how to create your own basic AFL model, using publicly available data. The output will be the odds for each team to win. The aim of this tutorial is not to teach you how to code; but rather for someone with very little programming experience to understand exactly what is being done.\n",
    "\n",
    "For tutorials on Python, and data science, I highly recommend checking out [Datacamp](https://www.datacamp.com/) or [Dataquest](https://www.dataquest.io/). These are free resources that will provide you with the basics of Python and data science fundamentals.\n",
    "\n",
    "The tutorial will be relatively short. For the full process of a typical data science project, feel free to read any of the predictive model walkthroughs on [Betfair's Github](https://github.com/betfair-datascientists/predictive-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in The Data\n",
    "First, we will read in the data and explore the columns within the dataset. I have condensed the columns down to some key statistics for simplicity, but full AFL datasets are available using the [fitzRoy](https://github.com/jimmyday12/fitzRoy) R package or elsewhere online.\n",
    "\n",
    "I have collated the data and we will only use a subset of that data for this presentation. Specifically, we'll use the median supercoach score and the elos of each team as features in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the last 9 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have the median supercoach scores for each team, as well as the margin, result and each team's Elo score before the game. Let's take a quick look at the correlation between median supercoach scores and Elo scores with margin, so we can see if these look like they could be good predictors of margin/winning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlations of our columns to margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like supercoach and Elo are highly correlated with margin. These could be quality predictors of margin/winning. However, we need to ensure that we only use statistics that we have access to before the game. Currently we're using supercoach scores from after the game. This leaks the result. Instead we need to use average supercoach scores from <i>previous games</i> to predict the <i>current game</i>.\n",
    "\n",
    "## Feature Creation\n",
    "A \"feature\" is the stat in the data which we believe will allow our model to predict the outcome better. For example, we can use Elo as a feature because it will obviously allow the model to learn that higher Elos are more likely to beat low Elos.\n",
    "\n",
    "We're only going to use two features in this model: Elo for each team, and average supercoach scores over the past 10 games.\n",
    "\n",
    "Let's calculate the average supercoach score for each team for their past 10 matches. To do this, we need to reshape the data from having two teams on each row to only one team on each row (similar to going from a wide dataframe to a long dataframe). We can then find each team's average supercoach scores for the past 10 matches, and then join these stats back to our original dataframe.\n",
    "\n",
    "### Convert DataFrame from Wide to Long\n",
    "We need to reshape the dataframe by appending the team 2's data to team 1's data. This is because if use the current shape to calculate moving averages for the home team, we won't include the games where the team plays away. The image below depicts how we will be reshaping the data.\n",
    "\n",
    "![Wide to Long](wide_to_long.png \"Wide to Long\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe from wide to long\n",
    "\n",
    "# Get team 1's stats in a dataframe\n",
    "\n",
    "# Get team 2's stats in a dataframe\n",
    "\n",
    "# Append these dataframes together to get a long dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the last 5 rows of the long df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Moving Averages for Supercoach Scores\n",
    "As you can see, we now have a dataframe with one team on each row. Let's calculate the average supercoach score for each team over the past 10 games. This piece of code groups the data by the team and then calculates a \"rolling\" average (an average over a certain amount of games) for the last 10 games. It then shifts the data up so as to not include the current game in the calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create supercoach average for the last 10 games played. Call it supercoach_average_last_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at each team's average last 10 supercoach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at each team's last average 10 supercoach scores and order it from highest to lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the top sides generally have a higher supercoach average, whereas the bottom sides like Gold Coast, have a lower average supercoach score. Essendon are at the top as they are natually a high scoring supercoach team and also had a strong last 10 games of the 2018 season. Richmond are next, which is expected as they were favourites going into the finals. Our data doesn't include 2018 finals. If it did, we could expect Collingwood and West Coast to be higher up the ladder supercoach average ladder.\n",
    "\n",
    "## Join Features To Original DataFrame\n",
    "Let's now merge these average stats back to our original dataframe and use them to create a simple machine learning model. We will then predict the first round of 2019, to see what our model would've given us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put dataframe back into individual rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View last 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling With H2O\n",
    "Now that we have our features (elo for each team and average supercoach score), let's create a model. To simplify things, we're going to use H2O's AutoML function, which automatically creates many models, tunes each model and returns the best model with the highest/lowest metric. For example, if you want a model to be created based on the highest accuracy of choosing the winner, you could use accuracy as your metric. First, let's create a training set, which is the data which the model will be \"trained\" on. We will then use the model to predict the first round of 2019. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise h2o session\n",
    "\n",
    "# Create a training set - all the data up to 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an AutoML object\n",
    "\n",
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the first round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the round 1 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the round 1 predictions to the test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
